{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7470f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b24389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c5954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e5cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the map image\n",
    "image = cv2.imread('/home/usama/Downloads/low_quality_pics/mo_ash_grove.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to create a binary image\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Perform morphological operations to remove noise and fill gaps\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "morph = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, hierarchy = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter the contours to only include the specific area you want to mask\n",
    "filtered_contours = []\n",
    "for c in contours:\n",
    "    area = cv2.contourArea(c)\n",
    "    if area > 1000 and area < 10000:\n",
    "        filtered_contours.append(c)\n",
    "\n",
    "# Create a new binary image containing only the pixels within the filtered contours\n",
    "mask = np.zeros_like(morph)\n",
    "cv2.drawContours(mask, filtered_contours, -1, 255, -1)\n",
    "\n",
    "# Create a new image that contains only the pixels in the original image that correspond to the pixels in the mask image\n",
    "masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "# Save the masked image\n",
    "cv2.imwrite('masked_image.png', masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4790340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/usama/usama-dev/Usama_notebooks_and_python_files/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3e257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to downsample the high resolution image \n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"/home/usama/usama-dev/image_super_resolution_models/bsrgan-pip/data/input/il_dixmoor.png\")\n",
    "\n",
    "# Get the dimensions of the image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Calculate the new dimensions of the downsampled image\n",
    "new_height = int(height/2.16)\n",
    "new_width = int(width/2.16)\n",
    "\n",
    "# Resize the image using the calculated dimensions and interpolation method\n",
    "downsampled_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Save the downsampled image to disk\n",
    "cv2.imwrite(\"downsampled_image1.png\", downsampled_image)\n",
    "\n",
    "# Display the original and downsampled images\n",
    "#cv2.imshow(\"Original Image\", image)\n",
    "#cv2.imshow(\"Downsampled Image\", downsampled_image)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603bf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"/home/usama/usama-dev/edge-connect/examples/images/downsampled_image11.png\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply adaptive thresholding to segment the image\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Find contours in the thresholded image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an empty mask with the same dimensions as the original image\n",
    "mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "# Iterate through the contours and draw them on the mask\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour\n",
    "    area = cv2.contourArea(contour)\n",
    "    # Filter out contours that are too small or too large\n",
    "    if area > 300 and area < 500:\n",
    "        cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "\n",
    "# Display the mask\n",
    "#cv2.imshow(\"Mask\", mask)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# Save the mask to disk\n",
    "cv2.imwrite(\"/home/usama/usama-dev/edge-connect/examples/masks/downsampled_image11_mask.png\", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07528537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('/home/usama/usama-dev/lama/test_image/downsampled_image0.png')\n",
    "patch_size = 400 # You can adjust the patch size to your desired value\n",
    "patches = []\n",
    "for i in range(0, img.shape[0], patch_size):\n",
    "    for j in range(0, img.shape[1], patch_size):\n",
    "        patch = img[i:i+patch_size, j:j+patch_size]\n",
    "        patches.append(patch)\n",
    "mask = np.zeros_like(img)\n",
    "for i in range(0, img.shape[0], patch_size):\n",
    "    for j in range(0, img.shape[1], patch_size):\n",
    "        mask[i:i+patch_size, j:j+patch_size] = 255\n",
    "cv2.imwrite('mask_image.jpg', mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/usama/usama-dev/lama/test_image/downsampled_image0.png')\n",
    "print(img)\n",
    "x1, y1, x2, y2 = 100, 100, 300, 300 #\n",
    "patch = img[y1:y2, x1:x2]\n",
    "gray_patch = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(gray_patch, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('patch.png', patch)\n",
    "cv2.imwrite('mask.png', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027a366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('/home/usama/usama-dev/lama/test_image/downsampled_image0.png')\n",
    "\n",
    "\n",
    "# Extract a patch from the image\n",
    "x, y, w, h = 500, 500, 200, 200\n",
    "patch = image[y:y+h, x:x+w]\n",
    "\n",
    "# Save the patch image to disk\n",
    "cv2.imwrite('patch.jpg', patch)\n",
    "\n",
    "# Convert the patch image to grayscale\n",
    "gray_patch = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to create a binary mask\n",
    "thresh = cv2.threshold(gray_patch, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# Save the mask image to disk\n",
    "cv2.imwrite('mask0.png', thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c887c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load the original input image and display it to our screen\n",
    "image = cv2.imread('/home/usama/usama-dev/lama/test_image/downsampled_image0.png')\n",
    "#cv2.imshow(\"Original\", image)\n",
    "# a mask is the same size as our image, but has only two pixel\n",
    "# values, 0 and 255 -- pixels with a value of 0 (background) are\n",
    "# ignored in the original image while mask pixels with a value of\n",
    "# 255 (foreground) are allowed to be kept\n",
    "mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "cv2.rectangle(mask, (500, 500), (400, 400), 255, -1)\n",
    "#cv2.imshow(\"Rectangular Mask\", mask)\n",
    "# apply our mask -- notice how only the person in the image is\n",
    "# cropped out\n",
    "masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imwrite('masked.png', masked)\n",
    "#cv2.imshow(\"Mask Applied to Image\", masked)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82797da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for generating  number of gray scale rectangles on the mask image \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the input image\n",
    "img = cv2.imread('/home/usama/downsampled_image1.png')\n",
    "\n",
    "# Create a black mask image with the same size as the input image\n",
    "mask = np.zeros_like(img)\n",
    "\n",
    "# Define the rectangular windows\n",
    "rectangles = [\n",
    "   ((100, 100), (200, 200)),\n",
    "    #((300, 300), (400, 400))\n",
    "    #((500, 500), (800, 800))\n",
    "    #((700, 700), (1000, 1000))\n",
    "    #((900, 900), (1000, 1000)),\n",
    "    #((1000, 1000), (1200, 1200))\n",
    "]\n",
    "\n",
    "# Draw the rectangles on the mask image\n",
    "for rect in rectangles:\n",
    "    cv2.rectangle(mask, rect[0], rect[1], (255, 255, 255), -1)\n",
    "    \n",
    "\n",
    "# Use the mask image to mask out the regions of the input image that correspond to the rectangular windows\n",
    "# Convert the patch image to grayscale\n",
    "gray_patch = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to create a binary mask\n",
    "thresh = cv2.threshold(gray_patch, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "cv2.imwrite('downsampled_image_masked11.png', thresh)\n",
    "\n",
    "#masked_img = cv2.bitwise_and(img, mask)\n",
    "#cv2.imwrite('masked1122.png', masked_img)\n",
    "\n",
    "# Display the masked image\n",
    "#cv2.imshow('Masked Image', masked1122_img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcfe2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the rectangle in the input image and generate its mask image.but the patch in the mask image is rgb patch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the input image\n",
    "img = cv2.imread('/home/usama/downsampled_image1.png')\n",
    "\n",
    "# Create a black mask image with the same size as the input image\n",
    "mask = np.zeros_like(img)\n",
    "\n",
    "# Define the rectangular windows\n",
    "rectangles = [\n",
    "    ((100, 100), (200, 200)),\n",
    "    #((300, 300), (400, 400))\n",
    "   # ((500, 500), (800, 800)),\n",
    "    #((700, 700), (1000, 1000)),\n",
    "    #((900, 900), (1000, 1000)),\n",
    "    #((1000, 1000), (1200, 1200))\n",
    "]\n",
    "\n",
    "# Draw the rectangles on the mask image\n",
    "for rect in rectangles:\n",
    "    cv2.rectangle(mask, rect[0], rect[1], (255, 255, 255), -1)\n",
    "\n",
    "# Use the mask image to mask out the regions of the input image that correspond to the rectangular windows\n",
    "masked_img = cv2.bitwise_and(img, mask)\n",
    "cv2.imwrite('downsampled_image1_masked.png', masked_img)\n",
    "\n",
    "# Display the masked image\n",
    "#cv2.imshow('Masked Image', masked_img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5685c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for finding the rectangles in the image and then make it masks and the result is saved in current directory\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread('/home/usama/usama-dev-test/output_image11.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply edge detection\n",
    "edges = cv2.Canny(gray_img, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate through the contours and identify the rectangle boxes\n",
    "masks = []\n",
    "for contour in contours:\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > 1000:  # Filter out small contours that may not be rectangles\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "        if len(approx) == 4:  # If the contour has 4 corners, it's likely a rectangle\n",
    "            rect = cv2.minAreaRect(approx)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            mask = np.zeros_like(gray_img)\n",
    "            cv2.fillPoly(mask, [box], 255)\n",
    "            masks.append(mask)\n",
    "\n",
    "# Combine the masks\n",
    "final_mask = np.zeros_like(gray_img)\n",
    "for mask in masks:\n",
    "    final_mask = cv2.bitwise_or(final_mask, mask)\n",
    "#gray_patch = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "# Apply the mask\n",
    "result = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "#thresh = cv2.threshold(gray_patch, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "#patch = cv2.imwrite(\"Resultant_masked_image219.jpg\",result)\n",
    "\n",
    "gray_patch = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to create a binary mask\n",
    "thresh = cv2.threshold(gray_patch, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# Save the mask image to disk\n",
    "cv2.imwrite('mask0021999.png', thresh)\n",
    "# Display the result\n",
    "#cv2.imshow('Original Image', img)\n",
    "#cv2.imshow('Masked Image', result)\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fadc49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2240, 2880, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('/home/usama/Downloads/low_quality_pics/mo_ash_grove.jpg')\n",
    "\n",
    "# Get the original image dimensions\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Calculate the desired dimensions\n",
    "new_width = ((width - 1) // 320 + 1) * 320\n",
    "new_height = ((height - 1) // 320 + 1) * 320\n",
    "\n",
    "# Calculate the amount of padding required\n",
    "pad_width = new_width - width\n",
    "pad_height = new_height - height\n",
    "\n",
    "# Calculate the padding amounts for each side\n",
    "top = pad_height // 2\n",
    "bottom = pad_height - top\n",
    "left = pad_width // 2\n",
    "right = pad_width - left\n",
    "\n",
    "# Apply padding to the image\n",
    "padded_image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "padded_width=padded_image[0]\n",
    "print(padded_image.shape)\n",
    "\n",
    "# Display the padded image\n",
    "#cv2.imshow('Padded Image', padded_image)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = [(startX1, startY1, endX1, endY1), (startX2, startY2, endX2, endY2), ...]\n",
    "\n",
    "adjusted_boxes = []\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    startX = max(0, startX)\n",
    "    startX = min(startX, 320)\n",
    "\n",
    "    startY = max(0, startY)\n",
    "    startY = min(startY, 320)\n",
    "\n",
    "    endX = max(0, endX)\n",
    "    endX = min(endX, 320)\n",
    "\n",
    "    endY = max(0, endY)\n",
    "    endY = min(endY, 320)\n",
    "\n",
    "    adjusted_boxes.append((startX, startY, endX, endY))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
